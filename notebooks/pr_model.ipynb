{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc9cda7-fa12-4f07-9b6b-3042123ea8d5",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae79d9a7-c3fc-42df-9ef1-8469f5292f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b1a34f-3df1-44c3-807c-96d913f88c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 19:25:33.627074: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-21 19:25:33.678202: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-21 19:25:34.470651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import models\n",
    "except ImportError:\n",
    "    print('Please upload models.py to you current directory')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9d5896-7a50-4b2f-9b17-78d2a558612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/cve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dee4138-3769-4e2d-b278-d8b2b1dc9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:120000]\n",
    "test = df[120000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da15d4cf-5006-41d9-a36f-93f8936835d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BERTmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a16d164-d862-449a-8236-dc2fd8c2d7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ced90f0-ba99-4cef-b326-ed59e4c36968",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'privileges_required'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852c1421-d8e4-4858-9f4d-2b15cced5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_model = BERTmodel('privileges_required', train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b0a909-3f78-4954-8e75-3576612d8339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch 2,000  of  13,500.    Elapsed: 0:13:25.\n",
      "  Batch 4,000  of  13,500.    Elapsed: 0:26:49.\n",
      "  Batch 6,000  of  13,500.    Elapsed: 0:40:13.\n",
      "  Batch 8,000  of  13,500.    Elapsed: 0:53:37.\n",
      "  Batch 10,000  of  13,500.    Elapsed: 1:07:02.\n",
      "  Batch 12,000  of  13,500.    Elapsed: 1:20:31.\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epoch took: 1:30:33\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.41\n",
      "  Validation took: 0:03:16\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch 2,000  of  13,500.    Elapsed: 0:13:25.\n",
      "  Batch 4,000  of  13,500.    Elapsed: 0:42:40.\n",
      "  Batch 6,000  of  13,500.    Elapsed: 1:16:15.\n",
      "  Batch 8,000  of  13,500.    Elapsed: 1:49:49.\n",
      "  Batch 10,000  of  13,500.    Elapsed: 2:23:24.\n",
      "  Batch 12,000  of  13,500.    Elapsed: 2:57:00.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epoch took: 3:22:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation Loss: 0.45\n",
      "  Validation took: 0:08:16\n",
      "\n",
      "Training complete!\n",
      "Total training took 5:04:10 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1:30:33</td>\n",
       "      <td>0:03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3:22:06</td>\n",
       "      <td>0:08:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.46         0.41           0.86       1:30:33         0:03:16\n",
       "2               0.36         0.45           0.87       3:22:06         0:08:16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model.train(epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0796a438-6a1d-42f8-8661-82d0f1598c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8106806950422445"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bec436e-8ee8-481c-ae97-6b09c63d8ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8106806950422445, 'precision': 0.8106806950422445, 'recall': 0.8106806950422445, 'f1': 0.8106806950422445, 'mcc': 0.6561289979997119, 'cm': array([[15854,  1292,    92],\n",
      "       [ 3008,  7818,   223],\n",
      "       [  657,   666,  1755]])}\n"
     ]
    }
   ],
   "source": [
    "print(pr_model.getClassificationStats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21faeee0-55ca-4cae-a54d-08daac24e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_model.saveModel()\n",
    "pr_model.savePredictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961423b-106d-4431-9cc0-7117952956d7",
   "metadata": {},
   "source": [
    "### Push model to huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c9240b-3d0b-4e62-b605-b7e09c204ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56b9d395-b7fa-4281-bd7e-dae2b03243a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010a7a0b7fd5413a8a167ccf859b896a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1639c93-5bd6-4220-8dff-a69d17b2db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d1ebe7-2414-4b06-b327-53a4d4a4019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_model = BertForSequenceClassification.from_pretrained(f\"./{metric}_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90ce1c00-bc14-4b8c-99d6-b0931080b3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541b813b582f49f98a1e78a39804c348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Vijaybhk/Privileges_Required-BERT/commit/50f501d12b7ccd51791a46dcb88804e9ec460c1c', commit_message='Upload BertForSequenceClassification', commit_description='', oid='50f501d12b7ccd51791a46dcb88804e9ec460c1c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model.push_to_hub(f\"Vijaybhk/{metric.title()}-BERT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
