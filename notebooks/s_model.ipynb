{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc9cda7-fa12-4f07-9b6b-3042123ea8d5",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae79d9a7-c3fc-42df-9ef1-8469f5292f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b1a34f-3df1-44c3-807c-96d913f88c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 03:43:19.399907: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-22 03:43:19.450319: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 03:43:20.212040: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import models\n",
    "except ImportError:\n",
    "    print('Please upload models.py to you current directory')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9d5896-7a50-4b2f-9b17-78d2a558612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/cve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dee4138-3769-4e2d-b278-d8b2b1dc9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:120000]\n",
    "test = df[120000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da15d4cf-5006-41d9-a36f-93f8936835d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BERTmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a16d164-d862-449a-8236-dc2fd8c2d7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ced90f0-ba99-4cef-b326-ed59e4c36968",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'scope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "852c1421-d8e4-4858-9f4d-2b15cced5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTmodel(metric, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b0a909-3f78-4954-8e75-3576612d8339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch 2,000  of  13,500.    Elapsed: 0:17:41.\n",
      "  Batch 4,000  of  13,500.    Elapsed: 0:37:50.\n",
      "  Batch 6,000  of  13,500.    Elapsed: 0:57:59.\n",
      "  Batch 8,000  of  13,500.    Elapsed: 1:18:05.\n",
      "  Batch 10,000  of  13,500.    Elapsed: 1:38:12.\n",
      "  Batch 12,000  of  13,500.    Elapsed: 1:58:18.\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epoch took: 2:13:22\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.16\n",
      "  Validation took: 0:04:59\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch 2,000  of  13,500.    Elapsed: 0:19:58.\n",
      "  Batch 4,000  of  13,500.    Elapsed: 0:40:07.\n",
      "  Batch 6,000  of  13,500.    Elapsed: 1:00:15.\n",
      "  Batch 8,000  of  13,500.    Elapsed: 1:20:24.\n",
      "  Batch 10,000  of  13,500.    Elapsed: 1:40:32.\n",
      "  Batch 12,000  of  13,500.    Elapsed: 2:00:40.\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epoch took: 2:15:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.14\n",
      "  Validation took: 0:04:56\n",
      "\n",
      "Training complete!\n",
      "Total training took 4:39:04 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2:13:22</td>\n",
       "      <td>0:04:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2:15:47</td>\n",
       "      <td>0:04:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.16         0.16           0.97       2:13:22         0:04:59\n",
       "2               0.13         0.14           0.97       2:15:47         0:04:56"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0796a438-6a1d-42f8-8661-82d0f1598c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446197991391678"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bec436e-8ee8-481c-ae97-6b09c63d8ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9446197991391678, 'precision': 0.9446197991391678, 'recall': 0.9446197991391678, 'f1': 0.9446197991391678, 'mcc': 0.8361938788353562, 'cm': array([[23867,   492],\n",
      "       [ 1245,  5761]])}\n"
     ]
    }
   ],
   "source": [
    "print(model.getClassificationStats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21faeee0-55ca-4cae-a54d-08daac24e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saveModel()\n",
    "model.savePredictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961423b-106d-4431-9cc0-7117952956d7",
   "metadata": {},
   "source": [
    "### Push model to huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1c9240b-3d0b-4e62-b605-b7e09c204ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56b9d395-b7fa-4281-bd7e-dae2b03243a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273b30cb29a647238e414bb1431666f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1639c93-5bd6-4220-8dff-a69d17b2db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1d1ebe7-2414-4b06-b327-53a4d4a4019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(f\"./{metric}_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce1c00-bc14-4b8c-99d6-b0931080b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(f\"Vijaybhk/{metric.title()}-BERT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
